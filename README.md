# Building a Decision Tree From Scratch!
![This is an image](https://i.ytimg.com/vi/ZVR2Way4nwQ/maxresdefault.jpg)

<br/>

> ## ğŸ¤” Purpose
This is my second attempt at building an ML model from scratch in hopes of gaining a more fundamental understanding of the mathematical and statistical comopnents of ML algorithms. After doing some digging, I found random forests to be one of the simplest and most effective classifier algorithms. Since random forests are derived from (as the name might suggest) a forest of decision trees, I embarked on a mission to make a decision tree myself.

<br/>

> ## âš™ï¸ Process
1.  I watched videos and read articles in order to get a high-level understanding of the algorithm WITHOUT looking at any actual code. Sources I referenced heavily include [this video](https://www.youtube.com/watch?v=jVh5NA9ERDA) and [this video](https://www.youtube.com/watch?v=eM4uJ6XGnSM).
3. After much struggle, I was able to create accurate entropy and information gain calculators.
4. Built out the rest of the deciison tree class. My code is getting pretty ugly and redundant, but hey! At least I'm understanding it more. I'm prioritizing explicity and enumeration over implicity and vagueness.
5. Referenced more articles and videos (WIHTOUT CODE) to learn how to fit the decision tree model to a training set and then apply the fitted model to unseen data. After some trial-and-error, it was successful!

<br/>

> ## ğŸ‘ Victories and ğŸ‘ Challenges
1. ğŸ‘ Not sure how to approach creating a random forest from my decision trees. The probelm with coding from scratch is that there will likely be less foresight in the process, resulting in a constant need to rewite large chunks of code to accomodate for the next step.
2. ğŸ‘ Messy code with lots of redundancies and inefficient systems.
3. ğŸ‘ Created a working decision tree algorithm that can classify a datapoint from a dataset consisting of two features, two target classes, and one target. [insert link to file here](decision_tree_algorithm.ipynb)


<br/>

> ## ğŸ”­ Conclusion
I'd very much like to create a random forest algorithm from the ground up, but maybe not entirely on my own... I think it's time that I enlisted the help of tutorials from now on, rather than relying purely on my high-level understanding. As it turns out, I may actually end up learning more as opposed to beofre, where I would just create my own messy algorithms with a very point A to point B mindset, rather than a methodical one. Bottom line is, I'll do my best to ensure a balance between learning from other people's code and doing it myself so that I'm able to pick up concepts but translate and implement them into ways that I can understand and easily manipulate depending on the situation.
